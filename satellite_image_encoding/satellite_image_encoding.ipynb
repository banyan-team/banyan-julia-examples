{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Inference on Satellite Imagery with PyTorch+Julia (unreleased)\n",
    "\n",
    "In this notebook, we will walk through an example of using BanyanArrays to\n",
    "run a machine learning model, created in PyTorch (Python), on a collection of\n",
    "satellite images retrieved through a public API. See `model.ipynb` for the model\n",
    "definition in PyTorch (Python).\n",
    "\n",
    "We acknowledge the use of imagery provided by services from NASA's Global Imagery Browse Services (GIBS), part of NASA's Earth Observing System Data and Information System (EOSDIS).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring\n",
    "\n",
    "We will use Banyan to perform some data analysis on the Iris Dataset. To run this\n",
    "example, please ensure that you have set up your Banyan account.\n",
    "\n",
    "Run the first cell below to import `Banyan` and `BanyanDataFrames`.\n",
    "To configure your AWS credentials, run the second cell below and provide your\n",
    "AWS credentials when prompted. Banyan does not save your AWS credentials, but\n",
    "they are needed so that you can run your computation in your AWS account.\n",
    "Finally, run the third cell below to set your Banyan credentials and configure\n",
    "Banyan.\n",
    "\n",
    "You must pass your User ID and API Key to the `configure` function in order\n",
    "to authenticate. You can find this information on the Account page of the\n",
    "Banyan Dashboard. After running this cell, your credentials will be saved\n",
    "in `$HOME/.banyan/banyanconfig.toml` and will be read from that file in the\n",
    "future. This means that you only need to run this cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "using AWSS3\n",
    "using Banyan\n",
    "using BanyanArrays\n",
    "using BanyanImages\n",
    "using BanyanONNXRunTime\n",
    "using ImageCore\n",
    "using IterTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to configure the AWS CLI. When prompted, specify your AWS\n",
    "# credentials for the AWS account that you connected with Banyan. If you have\n",
    "# already configured the AWS CLI with the credentials for the account you have\n",
    "# configured with your Banyan account, you can skip this step.\n",
    "\n",
    "print(\"Enter AWS_ACCESS_KEY_ID: \\n\"); sleep(1)\n",
    "ENV[\"AWS_ACCESS_KEY_ID\"] = readline()\n",
    "print(\"Enter AWS_SECRET_ACCESS_KEY: \\n\"); sleep(1)\n",
    "ENV[\"AWS_SECRET_ACCESS_KEY\"] = readline()\n",
    "print(\"Enter AWS_DEFAULT_REGION: \\n\"); sleep(1)\n",
    "ENV[\"AWS_DEFAULT_REGION\"] = readline()\n",
    "\n",
    "print(\"AWS is now configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to configure Banyan. When prompted, provide your user ID and API\n",
    "# key. You can find these on the Account page of your Banyan dashboard.\n",
    "# If you have already configured Banyan, you can skip this step.\n",
    "\n",
    "print(\"Please enter your User ID: \\n\"); sleep(1)\n",
    "user_id = readline()\n",
    "print(\"Please enter your API Key: \\n\"); sleep(1)\n",
    "api_key = readline()\n",
    "\n",
    "# Configures Banyan client library with your Banyan credentials\n",
    "configure(user_id=user_id, api_key=api_key)\n",
    "print(\"Banyan is now configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a cluster\n",
    "\n",
    "For this example, you will need a Banyan cluster. You can either use an existing\n",
    "cluster or create a new cluster. Run the following code block and enter in either\n",
    "the name of an existing cluster or the name you would like to use for a new cluster.\n",
    "\n",
    "If you already have a cluster, you should specify its name, when prompted.\n",
    "\n",
    "If you would like to instead create a new cluster, provide a name and the name\n",
    "of the [Amazon EC2 key pair](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair) that you created during [Banyan setup](https://www.banyancomputing.com/creating-clusters).\n",
    "\n",
    "In the cell below, you can change `instance_type` to create a cluster with a\n",
    "different EC2 instance type that may have a larger amount of memory or workers.\n",
    "See the documentation [here](https://www.banyancomputing.com/banyan-jl-docs/create-cluster/) for the other parameters for creating a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster name for existing cluster or new cluster: \\n\"); sleep(1)\n",
    "cluster_name = readline()\n",
    "println(cluster_name)\n",
    "\n",
    "clusters = get_clusters()\n",
    "println(\"You have $(length(clusters)) clusters\")\n",
    "if !(haskey(clusters, cluster_name) && clusters[cluster_name].status == :running)\n",
    "    println(\"Creating new cluster $(cluster_name)\")\n",
    "    print(\"Name of SSH EC2 Key Pair: \\n\"); sleep(1)\n",
    "    ec2_key_pair_name = readline()\n",
    "    println(ec2_key_pair_name)\n",
    "    create_cluster(\n",
    "        name=cluster_name,\n",
    "        instance_type=\"t3.2xlarge\",\n",
    "        initial_num_workers=2,\n",
    "        ec2_key_pair_name=ec2_key_pair_name\n",
    "    )\n",
    "else\n",
    "    println(\"Using existing cluster $(cluster_name)\")\n",
    "end\n",
    "get_cluster(cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to S3\n",
    "\n",
    "In order to run inference using a model, the model should be either uploaded to\n",
    "Amazon S3 or should be on the Internet. In this example, we have a model locally,\n",
    "and we will upload it to the cluster's S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using AWSS3\n",
    "using FilePathsBase\n",
    "\n",
    "# Upload the model to S3\n",
    "model_save_path = \"image_compression_model.onnx\"\n",
    "s3_bucket_name = get_cluster_s3_bucket_name(cluster_name)\n",
    "\n",
    "cp(\n",
    "    Path(model_save_path),\n",
    "    S3Path(\"s3://$s3_bucket_name/$model_save_path\", config=Banyan.get_aws_config())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a session\n",
    "\n",
    "In order to perform any computation, we need to allocate resources on the cluster\n",
    "to perform the computation. To do this, create a job with a specified number\n",
    "of workers. The number of workers is correlated to the amount of parallelism\n",
    "and speedup you can get. The more workers, the more parallelized your computation\n",
    "can be and potentially the faster it can run. For this example, 2 workers should\n",
    "be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a session\n",
    "session_id = start_session(\n",
    "    cluster_name = cluster_name,\n",
    "    nworkers = 20,\n",
    "    print_logs = false,  # Toggle this if you want to view job output printed here in the notebook\n",
    "    store_logs_in_s3 = true,  # Toggle this if you do not want job logs to be saved\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running inference on data loaded from the Internet\n",
    "\n",
    "Run a model on each image to compress it to a vector encoding of length 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model path\n",
    "model_path = \"https://github.com/banyan-team/banyan-julia/raw/v22.02.13/BanyanONNXRunTime/test/res/image_compression_model.onnx\"\n",
    "\n",
    "# Load model\n",
    "model = BanyanONNXRunTime.load_inference(model_path, dynamic_axis=true)\n",
    "\n",
    "# Load data\n",
    "files = (  # 100\n",
    "    IterTools.product(1:10, 1:10),\n",
    "    (i, j) -> \"https://gibs.earthdata.nasa.gov/wmts/epsg4326/best/MODIS_Terra_CorrectedReflectance_TrueColor/default/2012-07-09/250m/6/$i/$j.jpg\"\n",
    ")\n",
    "data = BanyanImages.read_jpg(files; add_channelview=true)  # Specify `add_channelview` to add a dimension for the RGB channels\n",
    "data = BanyanArrays.map(x -> float(x), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cluster_s3_bucket_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model on data\n",
    "res = model(Dict(\"input\" => data))[\"output\"]\n",
    "\n",
    "# Create path in S3 to store the encodings\n",
    "offloaded() do \n",
    "    bucket = readdir(\"s3\")[1]\n",
    "    mkpath(\"s3/$bucket/encodings/\")\n",
    "end\n",
    "\n",
    "# Write each image encoding to a different file in Amazon S3\n",
    "res_vecs = mapslices(img -> [img], res, dims=2)[:]\n",
    "bc = BanyanArrays.collect(1:length(res_vecs))\n",
    "res = map(res_vecs, bc) do img_vec, i\n",
    "    if isdir(\"s3\")\n",
    "        bucket = readdir(\"s3\")[1]\n",
    "        write(\"s3/$bucket/encodings/part$i.txt\", string(img_vec))\n",
    "    end\n",
    "    0\n",
    "end\n",
    "\n",
    "compute_inplace(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_session(release_resources_now=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
