{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Dataset - DataFrames Analysis from S3\n",
    "\n",
    "In this notebook, we will walk through an example of using BanyanDataFrames to\n",
    "perform some data analysis on a NYC Taxi Dataset in S3 containing a few GB\n",
    "of data. This dataset is taken from the TLC Trip Record Data from nyc.gov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring\n",
    "\n",
    "We will use Banyan to perform some data analysis on the Iris Dataset. To run this\n",
    "example, please ensure that you have set up your Banyan account.\n",
    "\n",
    "Run the first cell below to import `Banyan` and `BanyanDataFrames`.\n",
    "To configure your AWS credentials, run the second cell below and provide your\n",
    "AWS credentials when prompted. Banyan does not save your AWS credentials, but\n",
    "they are needed so that you can run your computation in your AWS account.\n",
    "Finally, run the third cell below to set your Banyan credentials and configure\n",
    "Banyan.\n",
    "\n",
    "You must pass your User ID and API Key to the `configure` function in order\n",
    "to authenticate. You can find this information on the Account page of the\n",
    "Banyan Dashboard. After running this cell, your credentials will be saved\n",
    "in `$HOME/.banyan/banyanconfig.toml` and will be read from that file in the\n",
    "future. This means that you only need to run this cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "using Banyan\n",
    "using BanyanDataFrames\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to configure the AWS CLI. When prompted, specify your AWS\n",
    "# credentials for the AWS account that you connected with Banyan. If you have\n",
    "# already configured the AWS CLI with the credentials for the account you have\n",
    "# configured with your Banyan account, you can skip this step.\n",
    "\n",
    "print(\"Enter AWS_ACCESS_KEY_ID: \\n\"); sleep(1)\n",
    "ENV[\"AWS_ACCESS_KEY_ID\"] = readline()\n",
    "print(\"Enter AWS_SECRET_ACCESS_KEY: \\n\"); sleep(1)\n",
    "ENV[\"AWS_SECRET_ACCESS_KEY\"] = readline()\n",
    "print(\"Enter AWS_DEFAULT_REGION: \\n\"); sleep(1)\n",
    "ENV[\"AWS_DEFAULT_REGION\"] = readline()\n",
    "\n",
    "print(\"AWS is now configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to configure Banyan. When prompted, provide your user ID and API\n",
    "# key. You can find these on the Account page of your Banyan dashboard.\n",
    "# If you have already configured Banyan, you can skip this step.\n",
    "\n",
    "print(\"Please enter your User ID: \\n\"); sleep(1)\n",
    "user_id = readline()\n",
    "print(\"Please enter your API Key: \\n\"); sleep(1)\n",
    "api_key = readline()\n",
    "\n",
    "# Configures Banyan client library with your Banyan credentials\n",
    "configure(user_id=user_id, api_key=api_key)\n",
    "print(\"Banyan is now configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a cluster\n",
    "\n",
    "For this example, you will need a Banyan cluster. You can either use an existing\n",
    "cluster or create a new cluster. Run the following code block and enter in either\n",
    "the name of an existing cluster or the name you would like to use for a new cluster.\n",
    "\n",
    "If you already have a cluster, you should specify its name, when prompted.\n",
    "\n",
    "If you would like to instead create a new cluster, provide a name and the name\n",
    "of the [Amazon EC2 key pair](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-key-pairs.html#having-ec2-create-your-key-pair) that you created during [Banyan setup](https://www.banyancomputing.com/creating-clusters).\n",
    "\n",
    "In the cell below, you can change `instance_type` to create a cluster with a\n",
    "different EC2 instance type that may have a larger amount of memory or workers.\n",
    "See the documentation [here](https://www.banyancomputing.com/banyan-jl-docs/create-cluster/) for the other parameters for creating a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster name for existing cluster or new cluster: \n",
      "stdin> iris-df-analysis\n",
      "iris-df-analysis\n",
      "You have 38 clusters\n",
      "Using existing cluster iris-df-analysis\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Cluster(\"iris-df-analysis\", :running, \"\", \"arn:aws:s3:::banyan-cluster-data-iris-df-analysis-98dc37b9\")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cluster name for existing cluster or new cluster: \\n\"); sleep(1)\n",
    "cluster_name = readline()\n",
    "println(cluster_name)\n",
    "\n",
    "clusters = get_clusters()\n",
    "println(\"You have $(length(clusters)) clusters\")\n",
    "if !(haskey(clusters, cluster_name) && clusters[cluster_name].status == :running)\n",
    "    println(\"Creating new cluster $(cluster_name)\")\n",
    "    print(\"Name of SSH EC2 Key Pair: \\n\"); sleep(1)\n",
    "    ec2_key_pair_name = readline()\n",
    "    println(ec2_key_pair_name)\n",
    "    create_cluster(\n",
    "        name=cluster_name,\n",
    "        instance_type=\"t3.2xlarge\",\n",
    "        initial_num_workers=2,\n",
    "        ec2_key_pair_name=ec2_key_pair_name\n",
    "    )\n",
    "else\n",
    "    println(\"Using existing cluster $(cluster_name)\")\n",
    "end\n",
    "get_cluster(cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to S3\n",
    "\n",
    "To demonstrate how Banyan can be used with large data stored in Amazon S3, we\n",
    "will first upload a file to S3. This cell only needs to be run once. Also, note\n",
    "that this may take a while to run, due to the nature of S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] try_yieldto(undo::typeof(Base.ensure_rescheduled))",
      "    @ Base .\\task.jl:710",
      "  [2] wait",
      "    @ .\\task.jl:769 [inlined]",
      "  [3] wait(c::Base.GenericCondition{ReentrantLock})",
      "    @ Base .\\condition.jl:106",
      "  [4] take_buffered(c::Channel{Any})",
      "    @ Base .\\channels.jl:389",
      "  [5] take!",
      "    @ .\\channels.jl:383 [inlined]",
      "  [6] sync_end(c::Channel{Any})",
      "    @ Base.Experimental .\\experimental.jl:63",
      "  [7] macro expansion",
      "    @ .\\experimental.jl:101 [inlined]",
      "  [8] (::Downloads.var\"#9#18\"{IOStream, Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Nothing, Bool, Bool, String, Int64, Bool, Bool})(easy::Downloads.Curl.Easy)",
      "    @ Downloads C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:334",
      "  [9] with_handle(f::Downloads.var\"#9#18\"{IOStream, Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Nothing, Bool, Bool, String, Int64, Bool, Bool}, handle::Downloads.Curl.Easy)",
      "    @ Downloads.Curl C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Curl\\Curl.jl:60",
      " [10] #8",
      "    @ C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:298 [inlined]",
      " [11] arg_write(f::Downloads.var\"#8#17\"{Base.DevNull, Nothing, Vector{Pair{String, String}}, Float64, Nothing, Bool, Bool, String, Int64, Bool, Bool}, arg::IOStream)",
      "    @ ArgTools C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\ArgTools\\src\\ArgTools.jl:112",
      " [12] #7",
      "    @ C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:297 [inlined]",
      " [13] arg_read",
      "    @ C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\ArgTools\\src\\ArgTools.jl:61 [inlined]",
      " [14] request(url::String; input::Nothing, output::IOStream, method::Nothing, headers::Vector{Pair{String, String}}, timeout::Float64, progress::Nothing, verbose::Bool, throw::Bool, downloader::Nothing)",
      "    @ Downloads C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:296",
      " [15] (::Downloads.var\"#3#4\"{Nothing, Vector{Pair{String, String}}, Float64, Nothing, Bool, Nothing, String})(output::IOStream)",
      "    @ Downloads C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:209",
      " [16] arg_write(f::Downloads.var\"#3#4\"{Nothing, Vector{Pair{String, String}}, Float64, Nothing, Bool, Nothing, String}, arg::Nothing)",
      "    @ ArgTools C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\ArgTools\\src\\ArgTools.jl:101",
      " [17] #download#2",
      "    @ C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:208 [inlined]",
      " [18] download(url::String, output::Nothing)",
      "    @ Downloads C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.6\\Downloads\\src\\Downloads.jl:208",
      " [19] #invokelatest#2",
      "    @ .\\essentials.jl:708 [inlined]",
      " [20] invokelatest",
      "    @ .\\essentials.jl:706 [inlined]",
      " [21] do_download",
      "    @ .\\download.jl:33 [inlined]",
      " [22] download(url::String)",
      "    @ Base .\\download.jl:29",
      " [23] top-level scope",
      "    @ In[3]:6",
      " [24] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [25] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "using AWSS3\n",
    "\n",
    "data_path = \"https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-01.csv\"\n",
    "s3_bucket_name = get_cluster_s3_bucket_name(cluster_name)\n",
    "\n",
    "temp_path = download(data_path)\n",
    "cp(\n",
    "    Path(temp_path),\n",
    "    S3Path(\"s3://$s3_bucket_name/nyc_tripdata.csv\", config=Banyan.get_aws_config())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a job\n",
    "\n",
    "In order to perform any computation, we need to allocate resources on the cluster\n",
    "to perform the computation. To do this, create a job with a specified number\n",
    "of workers. The number of workers is correlated to the amount of parallelism\n",
    "and speedup you can get. The more workers, the more parallelized your computation\n",
    "can be and potentially the faster it can run. For this example, 2 workers should\n",
    "be sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job\n",
    "job_id = start_session(\n",
    "    cluster_name = cluster_name,\n",
    "    nworkers = 2,\n",
    "    print_logs = false,  # Toggle this if you want to view job output printed here in the notebook\n",
    "    store_logs_in_s3 = true,  # Toggle this if you do not want job logs to be saved\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing computation on a dataframe\n",
    "\n",
    "The following code compute several queries on the dataset.\n",
    "\n",
    "Note that the API for performing various operations on dataframes is the same as that\n",
    "of the DataFrames library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file\n",
    "s3_bucket_name = get_cluster_s3_bucket_name(cluster_name)\n",
    "df = read_csv(\n",
    "    \"s3://$s3_bucket_name/nyc_tripdata.csv\",\n",
    "    shuffled=true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute properties of the dataframe\n",
    "\n",
    "println(\"Number of rows: $(nrow(df))\")\n",
    "println(\"Number of columns: $(ncol(df))\")\n",
    "println(\"Size: $(size(df))\")\n",
    "println(\"Column names: $(names(df))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell filter all trips with distance longer than 1.0, groups by passenger count,\n",
    "and gets the average trip distance for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_trips = filter(\n",
    "    row -> row.trip_distance > 1.0,\n",
    "    df\n",
    ")\n",
    "gdf = groupby(long_trips, :passenger_count)\n",
    "trip_means = combine(gdf, :trip_distance => mean)\n",
    "\n",
    "trip_means = compute(trip_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup resources\n",
    "\n",
    "After running your desired computation, we suggest that you destroy your running\n",
    "job so that you are not charged for resources when you are not using them. You\n",
    "may choose to keep your cluster running.\n",
    "\n",
    "Run the following code block to destroy the job that you created in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Destroy job\n",
    "end_session(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code block to delete the cluster that you created in this\n",
    "example. This will delete all resources associated with the cluster, including\n",
    "the S3 bucket that contains job logs and data files.\n",
    "\n",
    "Since cluster creation can take up to 30 minutes, you may want to keep\n",
    "your cluster running if you want to run other computation (additional jobs) on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Do you want to destroy cluster $cluster_name? y/n \\n\"); sleep(1)\n",
    "destroy = readline()\n",
    "if destroy == \"y\"\n",
    "    delete_cluster(cluster_name)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
